{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bb63726-505f-45b0-b71c-edc53bc9b5e6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50da9d69-4f56-41e5-83eb-70b2c2e7195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, EsmConfig, AutoConfig\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import torch\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eebf3a-94ae-4e09-b7d7-8a225ebcb072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and temporary sets (70% train, 30% temp)\n",
    "# train_set, temp_set = train_test_split(combined, test_size=0.3, random_state=950806, stratify=combined['label'])\n",
    "\n",
    "# Further split the temporary set into validation and test sets (50% validation, 50% test)\n",
    "# valid_set, test_set = train_test_split(temp_set, test_size=0.5, random_state=950806, stratify=temp_set['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5274d842-a104-4082-8929-c13f70e97ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('/home/raylab/Zihao/BCR/ModelData/training_set.csv')\n",
    "valid_set = pd.read_csv('/home/raylab/Zihao/BCR/ModelData/valid_set.csv')\n",
    "test_set = pd.read_csv('/home/raylab/Zihao/BCR/ModelData/test_set.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3410ffdc-0d37-4fab-87ff-5b6e7210b7f0",
   "metadata": {},
   "source": [
    "# Preprocessing and Load Model from Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac74452-5fa4-447b-a6fb-6341f9ad8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqs = train_set['sequence'].tolist()\n",
    "train_labels = train_set['label'].tolist()\n",
    "valid_seqs = valid_set['sequence'].tolist()\n",
    "valid_labels = valid_set['label'].tolist()\n",
    "test_seqs = test_set['sequence'].tolist()\n",
    "test_labels = test_set['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eda974-c0f7-45cb-9de3-6d94983447a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/esm2_t6_8M_UR50D\"  # Example model; replace with your specific model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b827cca3-201f-461a-8a91-d9f62fa20714",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized = tokenizer(train_seqs)\n",
    "test_tokenized = tokenizer(test_seqs)\n",
    "valid_tokenized = tokenizer(valid_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be64b04-6704-441f-ae04-8eb3dbee41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "train_dataset = Dataset.from_dict(train_tokenized)\n",
    "test_dataset = Dataset.from_dict(test_tokenized)\n",
    "valid_dataset = Dataset.from_dict(valid_tokenized)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff30057d-c0f4-4abe-ab7f-540614aceaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.add_column(\"labels\", train_labels)\n",
    "test_dataset = test_dataset.add_column(\"labels\", test_labels)\n",
    "valid_dataset = valid_dataset.add_column(\"labels\", valid_labels)\n",
    "\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58595b35-ba80-4a8d-8081-8d923ae6d102",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d7dee-7ed4-473e-a423-6519a505753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d890eb3-ed85-474c-87f4-b776441bfdd0",
   "metadata": {},
   "source": [
    "# Hyperparameter and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac7599-176f-4d78-8481-14396d85f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.config\n",
    "config.hidden_dropout_prob = 0.3\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79577ad0-23cd-49b1-83b5-1c4c210d17ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"ESM2-finetuned-localization\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")# training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5efaef9-b532-43fd-917b-934fcbb15481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "import numpy as np\n",
    "\n",
    "metric = load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498fd1c9-1476-45dd-8a1f-7947ab423f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ace99f-48c4-4605-b2e2-bff8c0d4ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece10b4-a199-46a3-b710-a5bdcc919d3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20f3ac4-17ae-491f-a667-1f7739f8e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95746da4-3507-432a-ac66-5fe42b3f871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Convert logits to probabilities\n",
    "probabilities = softmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Determine the predicted class\n",
    "predicted_classes = np.argmax(probabilities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdce2e3-9fc9-45f4-b3e0-1d7a690e2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_classes)\n",
    "precision = precision_score(true_labels, predicted_classes)\n",
    "recall = recall_score(true_labels, predicted_classes)\n",
    "f1 = f1_score(true_labels, predicted_classes)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c35f16-7a88-4ed8-9637-bef2a6fea12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Compute ROC AUC\n",
    "roc_auc = roc_auc_score(true_labels, probabilities[:, 1])\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_classes)\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Compute classification report (precision, recall, F1-score)\n",
    "class_report = classification_report(true_labels, predicted_classes)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report)\n",
    "\n",
    "# Print ROC AUC\n",
    "print(\"\\nROC AUC:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57873022-0542-404c-ad2e-a0ebefd0f707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_predictions(true_labels, probabilities[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8382e788-d5f9-427a-b18c-a4ed8046a0be",
   "metadata": {
    "tags": []
   },
   "source": [
    "# BCR Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d4c82-4710-4056-b42c-ce618725f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BCR repertoire \n",
    "heavy_chains = pd.read_csv('BCR/ModelData/heavy_vdj_airr.tsv', sep='\\t')\n",
    "# heavy_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56521065-2258-4635-ab63-1ce3605c14c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "# Create a list to store the predictions\n",
    "predicted_labels = []\n",
    "predicted_probabilities = []\n",
    "# Iterate through each sequence in the DataFrame\n",
    "for sequence in heavy_chains['sequence_aa']:\n",
    "    # Tokenize the sequence using the tokenizer\n",
    "    encoded_sequence = tokenizer.encode_plus(sequence, return_tensors=\"pt\", max_length=256, truncation=True)\n",
    "    \n",
    "    # Move the input tensors to the appropriate device\n",
    "    input_ids = encoded_sequence['input_ids'].to(device)\n",
    "    attention_mask = encoded_sequence['attention_mask'].to(device)\n",
    "    \n",
    "    # Make predictions for the current sequence\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask=attention_mask).logits\n",
    "        \n",
    "    # Softmax to get probabilities\n",
    "    probability = torch.softmax(logits, dim=1).squeeze().tolist()[1]\n",
    "    # Take the argmax to get the predicted label\n",
    "    predicted_label = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Append to lists\n",
    "    predicted_labels.append(predicted_label)\n",
    "    predicted_probabilities.append(probability)\n",
    "\n",
    "# Add to df\n",
    "heavy_chains['predicted_label'] = predicted_labels\n",
    "heavy_chains['predicted_probability'] = predicted_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c73f7-c74c-42ac-8804-25d2fc6b2155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame based on the maximum predicted probability in each list\n",
    "heavy_chains_sorted = heavy_chains.sort_values(by='predicted_probability', ascending=False)\n",
    "\n",
    "# Reset the index after sorting\n",
    "heavy_chains_sorted.reset_index(drop=True, inplace=True)\n",
    "heavy_chains_sorted.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2823f730-c41f-4dcc-9b98-a3bddc009f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(heavy_chains['predicted_probability'], bins=20)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Distribution of predicted_probability')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07f9917-36fc-4956-bf8b-badd443863e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(heavy_chains['predicted_probability'], bins=20)  # Adjust the number of bins as needed\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency Distribution of predicted_probability')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb321a8-bf03-49e8-a5fc-c73ee9ab7374",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save Model and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c5d249-c295-4a18-a0b6-7b4079bbc1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = heavy_chains[heavy_chains['predicted_probability'] >=0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb8fd32-6834-4956-b980-6e7a4089d96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"ESM_fintuned/lr2e-4\")\n",
    "tokenizer.save_pretrained(\"ESM_fintuned/lr2e-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5784ed41-cd4d-4637-9c6e-c6bc222a9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates.to_csv('BCR/esm_candidates_low_threshold.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682f82a2-064f-46c0-a723-32cca98a2291",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4749f0-b1bf-4a52-a3ee-6c1499d4e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ESM2-finetuned-localization/checkpoint-23410'\n",
    "config = AutoConfig.from_pretrained(model_name, output_hidden_states=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7c70c-8918-4285-ae25-a20cdaaca96d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "# Move model to the appropriate device (cuda if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Prott5",
   "language": "python",
   "name": "prott5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
